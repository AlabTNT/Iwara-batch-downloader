import json, re, time, os, requests
from urllib.parse import urlsplit, unquote, unquote_plus
from pathlib import Path
from tqdm import tqdm
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

SAVE_DIR = "videos"
waitafterload = 10
REQUEST_TIMEOUT = 30

os.makedirs(SAVE_DIR, exist_ok=True)

def safe_filename(name: str, max_len=200) -> str:
    if not name:
        name = "untitled"
    name = unquote(name)
    name = re.sub(r'[\\/:*?"<>|\r\n\t]+', "_", name).strip()
    if len(name) > max_len:
        name = name[:max_len].rstrip()
    return name or "untitled"

def download_stream_to_file(url: str, path: str):
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
    with requests.get(url, stream=True, timeout=REQUEST_TIMEOUT, headers=headers) as r:
        r.raise_for_status()
        total = int(r.headers.get("content-length", 0))
        with open(path, "wb") as f, tqdm(total=total, unit="B", unit_scale=True, desc=os.path.basename(path)) as bar:
            for chunk in r.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    bar.update(len(chunk))

def make_driver_headless():
    options = Options()
    options.add_argument("--headless=new")
    options.add_argument("--mute-audio")
    options.add_argument("--autoplay-policy=no-user-gesture-required")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-gpu")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-logging")
    options.add_argument("--log-level=3")
    options.add_argument("--ignore-certificate-errors")
    service = Service(log_path="NUL")

    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64)")
    options.set_capability("goog:loggingPrefs", {"performance": "ALL"})
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    driver.set_page_load_timeout(60)
    return driver


def extract_videos_and_title(logs):
    video_urls = set()
    title = "untitled"
    title_urls= set()

    for entry in logs:
        try:
            message = json.loads(entry["message"])["message"]
        except Exception:
            continue
        method = message.get("method")
        params = message.get("params", {})
        if method == "Network.responseReceived":
            response = params.get("response", {})
            url = response.get("url", "")

            if "_Source.mp4" in url or "_540.mp4" in url:
                video_urls.add(unquote(url))    
                
            if url:
                if re.search(r"\.mp4(\?|$)", url, re.I):
                    title_urls.add(url)

    # å°è¯•ä»ç¬¦åˆæ¡ä»¶çš„è§†é¢‘ URL æå– title
    for u in title_urls:
        if "files.iwara.tv" in u:
            t = u.split("download=")[-1]
            try:
                decoded = unquote_plus(t or "")
                decoded = decoded.split("?", 1)[0].split("#", 1)[0].strip()
                decoded = re.sub(r'\.(mp4|m3u8|webm|mov|avi|mkv)$', '', decoded, flags=re.I)
                decoded = re.sub(r'\s+', ' ', decoded)
                title = safe_filename(decoded)
            except Exception:
                title = safe_filename(unquote_plus(t)) if t else "untitled"
            break
    
    backtitle = title
    try:
        title = title.replace("Iwara - ","")
        title = re.sub(r'\[[A-Za-z0-9]+\]', '', title)
        title = re.sub(r'\s+', ' ', title).strip()
        title = safe_filename(title)
    except:
        title=backtitle

    return video_urls, title

def crawl_one(url: str, driver=None):
    print(f"\nğŸš© å¤„ç†é¡µé¢: {url}")
    df=driver is None
    try:
        if not driver:
            driver = make_driver_headless()
        driver.get(url)
        time.sleep(waitafterload)
        logs = driver.get_log("performance")
        video_urls, title = extract_videos_and_title(logs)
        print("é¡µé¢æ ‡é¢˜ï¼š", title or "(æ— æ ‡é¢˜)")

        if not video_urls:
            print("âš ï¸ æœªæ‰¾åˆ°ç¬¦åˆ iwara.tv çš„åª’ä½“èµ„æºã€‚å°è¯•æ’­æ”¾å½•åˆ¶æŠ“å–...")
            wait = WebDriverWait(driver, 10)
            play_button = wait.until(EC.element_to_be_clickable((
                By.CSS_SELECTOR,
                "button.vjs-play-control.vjs-control.vjs-button"
            )))
            play_button.click()
            time.sleep(waitafterload)
            logs = driver.get_log("performance")
            video_urls,_= extract_videos_and_title(logs)
        
        if not video_urls:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘èµ„æºï¼Œè·³è¿‡æ­¤é“¾æ¥ã€‚")
            return False

        chosen = None
        for v in video_urls:
            if re.search(r"\.mp4(\?|$)", v, re.I):
                chosen = v
                break
        if not chosen:
            chosen = next(iter(video_urls))

        print("ğŸ¯ é€‰ä¸­ä¸‹è½½ï¼š", chosen)
        path = urlsplit(chosen).path
        ext = os.path.splitext(path)[1] or ".mp4"

        derived_name = title
        if derived_name:
            _t=os.path.splitext(derived_name)
            if not _t[1] or _t[1].lower() not in [".mp4", ".m3u8", ".webm", ".mov", ".avi", ".mkv"]:
                filename = derived_name + ext
            else:
                filename = derived_name
        else:
            filename = safe_filename(title) + ext

        out_path = os.path.join(SAVE_DIR, filename)
        if os.path.exists(out_path):
            print("ğŸ˜® æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ï¼š", out_path)
            return True
        
        download_stream_to_file(chosen, out_path)
        print("âœ… ä¸‹è½½å®Œæˆï¼š", out_path)
        return True

    except Exception as e:
        print("âš ï¸ å¤„ç†å‡ºé”™ï¼š", e)
    
    if df and driver:
        driver.quit()


def save_main(url):
    with open("iwara_urls.json", "r", encoding="utf-8") as f:
        urls = json.load(f)
    with open("iwara_urls.json", "w", encoding="utf-8") as f:
        json.dump([i for i in urls if i != url], f, ensure_ascii=False, indent=4)

def readin(readbook=True):
    if os.path.exists("iwara_urls.json"):
        with open("iwara_urls.json", "r", encoding="utf-8") as f:
            bookmarks = json.load(f)
    else:
        bookmarks = []

    if readbook is True:
        for p in Path('.').glob('*.html'):
            print("â„¹ï¸æ‰¾åˆ°å¯èƒ½çš„ä¹¦ç­¾æ–‡ä»¶ï¼š",p.name)
            with open(p.name, "r", encoding="utf-8") as f:
                html_content = f.read().splitlines()
                for i in html_content:
                    m = re.search(r'<DT><A HREF="([^"]+)"\s+ADD_DATE=', i)
                    if not m:
                        continue
                    url = m.group(1)
                    if "iwara.tv/video" not in url:
                        continue
                    bookmarks.append(url)
                    print("  â¤ æ·»åŠ é“¾æ¥ï¼š", url)
            os.remove(p.name)
            print("â„¹ï¸å·²å¤„ç†å¹¶åˆ é™¤ä¹¦ç­¾æ–‡ä»¶ï¼š",p.name)
    bookmarks = list(set(bookmarks))

    with open("iwara_urls.json", "w", encoding="utf-8") as f:
        json.dump(bookmarks, f, ensure_ascii=False, indent=4)
    print(f"â„¹ï¸ å·²åŠ è½½ iwara_urls.jsonï¼ŒåŒ…å« {len(bookmarks)} ä¸ªé“¾æ¥ã€‚")
    return bookmarks

def get_txt():
    urls=[]
    for p in Path('.').glob('*.txt'):
        print("â„¹ï¸æ‰¾åˆ°å¯èƒ½çš„æ–‡æœ¬æ–‡ä»¶ï¼š",p.name)
        with open(p.name, "r", encoding="utf-8") as f:
            for line in f:
                url = line.strip()
                if "iwara.tv/video" in url:
                    urls.append(url)
                    print("  â¤ æ·»åŠ é“¾æ¥ï¼š", url)
        os.remove(p.name)
        print("â„¹ï¸å·²å¤„ç†å¹¶åˆ é™¤æ–‡æœ¬æ–‡ä»¶ï¼š",p.name)
    return urls

def main(urls=[],driver=None):
    print("=== Iwara è§†é¢‘ä¸‹è½½å™¨ by AlabTNT ===")
    failed=[]
    print(f"ğŸŒŸ å¼€å§‹æ‰¹é‡ä¸‹è½½ï¼Œä»»åŠ¡å…±æœ‰ {len(urls)} ä¸ªé“¾æ¥ã€‚é¢„è®¡éœ€è¦æ—¶é•¿ï¼š{len(urls)*1.5:.1f} åˆ†é’Ÿ")
    for url in urls:
        try:
            success = crawl_one(url, driver=driver)
            if not success:
                failed.append(url)
            else:
                save_main(url)
        except Exception as e:
            print("æ•´ä½“å¤„ç†å¼‚å¸¸ï¼š", e)
    
    print("\n=== å¤„ç†å®Œæˆ ===")
    print("âœ… æˆåŠŸä¸‹è½½çš„è§†é¢‘ï¼š", len(urls) - len(failed),"/", len(urls))
    if failed:
        print("ğŸš¨ æ‰€æœ‰å°è¯•å¤±è´¥çš„è§†é¢‘é“¾æ¥ï¼š\n-","\n- ".join(failed))
    print("â„¹ï¸ è§†é¢‘å·²å­˜æ”¾åœ¨ï¼š", os.path.abspath(SAVE_DIR))
    print("\n\nä»»åŠ¡å®Œæˆï¼Œé€€å‡ºã€‚")

    if driver:
        driver.quit()
        
def routing():
    print("=== Iwara è§†é¢‘ä¸‹è½½å™¨ by AlabTNT ===")
    print("   1. åªæ‰¹é‡ä¸‹è½½ .json ä¸­çš„é“¾æ¥")
    print("   2. ä» .html ä¹¦ç­¾æ–‡ä»¶å¯¼å…¥å¹¶ä¸‹è½½ .json ä¸­çš„é“¾æ¥")
    print("   3. ä» .txt æ–‡ä»¶å¯¼å…¥å¹¶ä¸‹è½½ .json ä¸­çš„é“¾æ¥")
    print("   4(default). åŒæ—¶ä» .html ä¹¦ç­¾æ–‡ä»¶å’Œ .txt æ–‡ä»¶å¯¼å…¥å¹¶ä¸‹è½½ .json ä¸­çš„é“¾æ¥")
    print("   5. æ‰‹åŠ¨è¾“å…¥å•ä¸ªé“¾æ¥ä¸‹è½½")
    print("   e/q/6. é€€å‡ºç¨‹åº")
    driver=make_driver_headless()

    while True:
        print("â„¹ï¸ è¯·é€‰æ‹©è¿è¡Œæ¨¡å¼(1/2/3/4/5/6/e/q)ï¼š", end="")
        choice = input().strip()
        if choice == "1":
            print("âœ¨ æ¨¡å¼ï¼š1ï¼ˆä»….jsonï¼‰")
            urls = readin(False)
            main(urls, driver=driver)
        elif choice == "2":
            print("ğŸ“ æ¨¡å¼ï¼š2ï¼ˆ.htmlï¼‰")
            urls = readin(True)
            main(urls, driver=driver)
        elif choice == "3":
            print("ğŸ•¶ï¸ æ¨¡å¼ï¼š3ï¼ˆ.txtï¼‰")
            urls = get_txt()
            main(urls, driver=driver)
        elif choice == "4":
            print("ğŸ¯ æ¨¡å¼ï¼š4ï¼ˆ.txt+.htmlï¼‰")
            urls = readin(True)
            urls += get_txt()
            urls = list(set(urls))
            main(urls, driver=driver)
        elif choice == "5":
            print("ğŸ˜€ æ¨¡å¼ï¼š5ï¼ˆæ‰‹åŠ¨ï¼‰")
            while True:
                print("â„¹ï¸ è¯·è¾“å…¥ iwara.tv è§†é¢‘é“¾æ¥ï¼Œè¾“å…¥ exit é€€å‡ºï¼š", end="")
                url = input().strip()
                if "iwara.tv" in url:
                    crawl_one(url, driver=driver)
                elif url=="exit":
                    print("ğŸ‘‹ é€€å‡ºæ‰‹åŠ¨è¾“å…¥æ¨¡å¼ã€‚")
                    break
                else:
                    print("âš ï¸ è¾“å…¥çš„é“¾æ¥æ— æ•ˆã€‚")
        elif choice in ["e", "q", "6"]:
            print("ğŸ‘‹ é€€å‡ºç¨‹åºã€‚")
            if driver:
                driver.quit()
            return
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•ã€‚")
            
if __name__ == "__main__":
    routing()
